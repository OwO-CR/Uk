# 도커 스웜

여러 대의 서버를 클러스터로 만들어 자원을 병렬로 확장!

### 스웜 클래식과 도커 스웜 모드

여러 대의 도커 서버를 하나의 클러스터로 만들어 컨테이너를 생성하는 여러 기능을 제공.

2가지 종류

스웜 클래식 - 컨테이너로서의 스웜

도커 스웜 모드

**차이점**

스웜 클래식 여러 대의 도커 서버를 하나의 지점에서 사용하도록 단일 접근점을 제공

스웜 모드 : 마이크로서비스 아키텍처의 컨테이너를 다루기 위한 클러스터링 기능에 초점

분산 코디네이터, 클러스터 서버 매니저, 에이전트와 같은 클러스터 툴 제공 여부
→ 스웜

## 스웜 모드

매니저 노드와 워커 노드로 구성.

`docker swarm init --advertise-addr <manager_node_IP_address>` : Swarm 클러스터 시작

매니저 노드에 2개 이상의 네트워크 인터페이스 카드가 있을 경우 어느 IP 주소로 매니저에 접근해야 할지 다른 노드에 알려줄 필요가 있음.

ex) 172.17.0.5 / 192.168.0.100 두 개 존재 시, 스웜 클러스터 내 사용할 IP 주소 지정
→ 전자가 Private, 후자가 Public IP라면 후자를 `--advertise-addr`에 지정,
→ 다른 노드가 해당 노드에 접근할 수 있게 설정한다.

출력 결과 중 `docker swarm join` 명령어는 새로운 워커 노드를 스웜 클러스터에 추가할 때 사용된다.

`--token` : 사용된 토큰 값은 새로운 노드를 해당 스웜 클러스터에 추가하기 위한 비밀키.

> 스웜 클러스터를 구성하기 전에 포트를 각 호스트 머신에서 열어두는 것을 잊지 말자!
> 

`docker node ls` : 매니저 노드에서 입력, swarm cluster 목록 출력

`docker swarm join-token manager` / `docker swarm join-token worker` : 노드 추가를 위한 token 확인

`docker swarm join-token --rotate manager` (or worker) : token 갱신

`docker swarm leave` : 해당 워커 노드에서 입력 → 스웜 모드 해제 → Down (manager의 경우 `--force` 옵션 추가)

`docker node rm` : 매니저 노드에서 해당 워커 노드 삭제.

`docker node promote` / `docker node demote` : 매니저 → 워커 / 워커 → 매니저

스웜 모드에서 제어하는 단위는 컨테이너가 아닌 서비스.

서비스는 같은 이미지에서 생성된 컨테이너의 집합.
서비스를 제어하면 해당 서비스 내의 컨테이너에 같은 명령이 수행된다.
서비스 내에 컨테이너는 1개 이상 존재할 수 있으며, 컨테이너들은 각 워커 노드와 매니저 노드에 할당.
이러한 컨테이너들을 Task라고 한다.

스웜 스케줄러는 컨테이너를 할당한 적합한 노드 선정 → 해당 노드에 컨테이너를 분산해서 할당.

이처럼 함께 생성된 컨테이너를 레플리카라고 하며, 서비스에 설정된 레플리카의 수만큼의 컨테이너가 스웜 클러스터 내에 존재해야 한다.

롤링 업데이트 : 일괄 업데이트 필요 시, 컨테이너들의 이미지를 순서대로 변경해 지속적인 서비스 가능하다.

**서비스 생성** `docker service ~~` : 서비스를 제어하는 도커 명령어는 매니저 노드에서만 사용할 수 있다.

`docker service ls` : 스웜 클러스터 내 서비스 목록

`docker service ps [서비스 이름]` : 서비스의 자세한 정보 확인 (서비스 내 컨테이너의 목록, 상태, 할당된 노드의 위치)

`docker service rm` : 서비스 삭제 (서비스의 상태 관계 없이 서비스의 컨테이너를 바로 삭제)

nginx 웹 서버 서비스 생성하기

`docker service create --name [서비스 이름] \
—replicas 2 \
-p 80:80 \
nginx`

→ -p 80:80 를 입력함으로써 스웜 클러스터 자체에 포트를 개방했다고 생각하자!

→ 스웜 클러스터 내 어떠한 노드로 접근해도 해당 서비스의 웹 서버 접근 가능하다!

`docker service scale [서비스 이름]=[num]` : 레플리카 수 조정

컨테이너가 각 컨테이너들이 호스트의 80번 포트에 연결된 것이 아니며,
실제로는 각 노드 80번 포트로 들어온 요청을 레플리카 개수의 컨테이너 중 1개로 redirect!
→ 각 호스트의 어느 노드로 접근하든 num개의 컨테이너 중 1개에 접근한다.

**global 서비스** : `docker service create` 명령어에 `--mode global` 추가
스웜 클러스터 내에서 사용할 수 있는 모든 노드에 컨테이너를 반드시 하나씩 생성한다.

새로운 노드를 추가하거나 다운됐던 노드를 다시 복구했을 때 서비스의 컨테이너 할당의 균형을 맞추기 위해서는 scale 명령어를 통해 컨테이너 수를 줄이고 다시 늘려야한다.

**서비스 롤링 업데이트**

각 컨테이너 레플리카를 10초 단위로, 한 번에 2개의 컨테이너에 업데이트를 수행.

`docker service create \
--replicas 4 \
--name myweb3 \
--update-delay 10s \
--update-parallelism 2 \
nginx:1.10`

**서비스 컨테이너에 설정 정보 전달하기 : config, secret**

- secret : 비밀번호, SSH 키, 인증서 키 등 (민감한 데이터)
- config : nginx, 레지스트리 설정 파일 등 (암호화 필요 없는 설정값)

**secret**

`docker secret create` 

**config**

`docker config create`

config는 입력된 값을 base64로 인코딩한 뒤 저장, base64 명령어로 디코딩하면 원래의 값을 확인할 수 있다.

### 도커 스웜 네트워크

**ingress 네트워크**

스웜 클러스터를 생성하면 자동으로 등록되는 네트워크, 스웜 모드를 사용할 때만 유효하다.
어떤 스웜 노드에 접근하더라도 서비스 내의 컨테이너에 접근할 수 있게 설정하는 라우팅 메시를 구성,
서비스 내의 컨테이너에 대한 접근을 라운드 로빈 방식으로 분산하는 로드 밸런싱을 담당.

**오버레이 네트워크**

`docker exec <CONTAINER_ID> ifconfig` : 컨테이너 내부에서 ifconfig 실행!
→ 가상 네트워크 인터페이스를 출력한다

ingress 네트워크는 오버레이 네트워크 드라이버를 사용한다.

오버레이 네트워크는 여러 개의 도커 데몬을 하나의 네트워크 풀로 만드는 네트워크 가상화 기술의 하나로,
도커에 오버레이 네트워크를 적용하면 여러 도커 데몬에 존재하는 컨테이너가 서로 통신할 수 있다.

**docker_gwbrdige 네트워크** : `docker network ls` 출력에서 ingress 말고 새롭게 추가된 네트워크.

오버레이 네트워크를 사용하지 않는 컨테이너는 기본적으로 존재하는 bridge 네트워크를 사용해 외부와 연결.
그러나 ingress를 포함한 모든 오버레이 네트워크는 이와 다른 bridge 네트워크인 **docker_gwbridge** 네트워트와 함께 사용!

해당 네트워크는 외부로 나가는 통신 및 오버레이 네트워크의 트래픽 종단점(VTEP) 역할을 담당한다.
네트워크 인터페이스 카드 중 eth1과 연결.

> **VTEP** (VXLAN Tunnel End Point) - VXLAN Tunnel 종단 역할을 수행한다.
Encapsulation과 Termination의 End point 역할을 수행한다.
End point : 데이터 센터의 브로드캐스트 도메인에 속해있는 서버를 뜻한다.
> 

**사용자 정의 오버레이 네트워크**

스웜 모드는 자체 key-value 저장소를 갖고 있으므로 별도의 구성 없이 사용자 정의 오버레이 네트워크 생성 및 사용 가능하다.

`docker network create \
--subnet 10.0.9.0/24 \
-d overlay \
myoverlay`

일반적인 `docker run` 명령어로 swarm SCOPE를 갖는 네트워크 사용 불가.
→ `docker run --net` 명령어로 스웜 모드의 오버레이 네트워크 사용하려면 네트워크 생성할 때 `--attachable` 추가.

`docker service create` 명령어에 `--network` 옵션을 이용하면 오버레이 네트워크를 서비스에 적용해 컨테이너 생성 가능.
→ 네트워크 인터페이스를 확인해보면 eth0에 오버레이 네트워크의 IP 주소가 할당.

> `-p` 명시 안 할 시, IP 대역이 할당된 네트워크 인터페이스가 컨테이너 존재하지 않는다.
이 때는 기본으로 사용하는 bridge network, 172.17.0.X 대역을 갖는 인터페이스 하나만 존재하게 된다.
> 

**서비스 디스커버리**

같은 컨테이너를 여러 개 만들어 사용 시 쟁점? → 새로 생성된 컨테이너 생성의 발견 혹은 없어진 컨테이너의 감지

ex) 서비스 B에 새로운 컨테이너 생성, 접근 방법?

→ ‘B’라는 이름으로 모두 접근 가능!

→ ‘A’의 입장에서는 서비스 B의 컨테이너 IP주소 알 필요도 없이 ‘B’ 서비스 이름만 알면 된다.

**스웜 모드 볼륨**

도커 데몬 run 에서 `-v` 옵션을 사용할 때 호스트와 디렉토리를 공유하는 경우 / 볼륨을 사용하는 경우에 대한 구분은 딱히 없었다.

- 호스트와 디렉토리를 공유하는 경우
`docker run -it --name host_dir_case -v /root:/root ubuntu:14.04`
- 도커 볼륨을 사용하는 겨
`docker run -it --name volume_case -v myvolume:/root ubuntu:14.04`

스웜 모드에선 이를 좀 더 명확히 해 볼륨을 사용한다.

서비스 생성할 때 `--mount` 옵션의 type 값에 volume을 지정한다.

**source** 는 사용할 볼륨 **target**은 컨테이너 내부에 마운트 될 디렉토리 위치

```jsx
docker service create --name ubuntu \
--mount type=volume,source=myvol,target=/root \
ubuntu:14.04
ping docker.com
```

서비스의 컨테이너에서 볼륨에 공유할 컨테이너의 디렉토리에 파일이 이미 존재하면 이 파일들은 볼륨에 복사, 호스트에서 별도의 공간을 차지
→ `volume-nocopy` 를 추가!

ex) /etc/vim 디렉토리 파일을 볼륨으로 복사

이미 파일이 존재하고, 해당 디렉토리에 빈 볼륨을 마운트하면 볼륨으로 파일이 복사 → `volume-nocopy`

**bind 타입**의 볼륨 생성 `type=bind` : 호스트와 디렉토리를 공유할 때 사용.

공유될 호스트의 디렉토리를 설정해야하므로 `source` 옵션을 반드시 명시!

한계가 있음.

→ 가장 좋은 방법: Persistent Storage (외부에 존재해 네트워크로 마운트할 수 있는 스토리지)

### 도커 스웜 모드 노드 다루기

특정 노드에 유지 보수 작업 수행 시, 해당 노드에 컨테이너를 할당하지 않게 할 수 있음.

→ 특정 노드의 AVAILABILITY를 설정!

`docker node update \
--availability <state> \
<node_name>`
 

**Active** : 노드가 서비스의 컨테이너를 할당 받을 수 있음.

**Drain** : 스웜 매니저의 스케줄러는 해당 노드에 컨테이너를 할당하지 않음, 실행 중인 컨테이너 중지 → active에 할당

**Pause** : 실행 중인 컨테이너가 중지되지 않음.

**노드 라벨** : 노드에 라벨을 추가하는 것은 노드를 분류하는 것과 비슷하다.

라벨은 key-value 형태를 가지며, key 값을 통해 노드를 구별할 수 있다.

`docker node update` 명령에서 `--label-add` 옵션을 사용하여 라벨을 설정할 수 있다.

**서비스 제약 설정**

`docker service create` 명령어에 `--constraint` 옵션을 추가, 서비스의 컨테이너가 할당될 노드의 종류를 선택할 수 있다.

1. node.labels 제약조건

`docker service create` 명령어에 `--constraint 'node.labels.storage == ssd'` ( != 사용 가능)

1. [node.id](http://node.id) 제약조건

[node.id](http://node.id) 조건에 노드의 ID를 명시하여 서비스의 컨테이너를 할당할 노드 선택 (다른 명령어와 달리 ID 전부를 입력해야 함)

1. node.hostname과 node.role 제약조건

`--constraint 'node.hostname == swarm-worker1` 

`--constarint 'node.role != manager'`

1. engine.labels 제약조건

도커 엔진, 즉 도커 데몬 자체에 라벨을 설정

`DOCKER_OPTS=" ... --label mylabel=worker2 --label mylabel2=second_worker ... "`

`--constraint 'engine.labels.mylabel == worker2'`